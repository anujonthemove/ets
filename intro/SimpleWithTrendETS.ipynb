{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0050 cost= 2.342288017 level0= 0.509123 pace0= 0.256525 alpha= 0.636935 beta= 0.751185\n",
      "Epoch: 0100 cost= 2.282846212 level0= 0.656364 pace0= 0.183702 alpha= 0.652713 beta= 0.72633\n",
      "Epoch: 0150 cost= 2.273410797 level0= 0.711394 pace0= 0.151309 alpha= 0.665275 beta= 0.711016\n",
      "Epoch: 0200 cost= 2.271527290 level0= 0.733715 pace0= 0.138503 alpha= 0.675239 beta= 0.699067\n",
      "Epoch: 0250 cost= 2.270964861 level0= 0.743322 pace0= 0.13372 alpha= 0.683217 beta= 0.689241\n",
      "Epoch: 0300 cost= 2.270703554 level0= 0.74776 pace0= 0.132154 alpha= 0.689681 beta= 0.681158\n",
      "Epoch: 0350 cost= 2.270549536 level0= 0.750015 pace0= 0.131855 alpha= 0.69496 beta= 0.67454\n",
      "Epoch: 0400 cost= 2.270450115 level0= 0.751305 pace0= 0.132028 alpha= 0.699292 beta= 0.669133\n",
      "Epoch: 0450 cost= 2.270383120 level0= 0.752136 pace0= 0.132353 alpha= 0.702859 beta= 0.664716\n",
      "Epoch: 0500 cost= 2.270339966 level0= 0.752729 pace0= 0.132701 alpha= 0.705802 beta= 0.661102\n",
      "Epoch: 0550 cost= 2.270309210 level0= 0.753182 pace0= 0.133024 alpha= 0.708233 beta= 0.658141\n",
      "Epoch: 0600 cost= 2.270288944 level0= 0.753542 pace0= 0.133309 alpha= 0.710244 beta= 0.655709\n",
      "Epoch: 0650 cost= 2.270274878 level0= 0.753836 pace0= 0.133553 alpha= 0.71191 beta= 0.653709\n",
      "Epoch: 0700 cost= 2.270266294 level0= 0.754078 pace0= 0.133759 alpha= 0.71329 beta= 0.652061\n",
      "Epoch: 0750 cost= 2.270259380 level0= 0.754279 pace0= 0.133932 alpha= 0.714434 beta= 0.650701\n",
      "Epoch: 0800 cost= 2.270254612 level0= 0.754447 pace0= 0.134077 alpha= 0.715383 beta= 0.649576\n",
      "Epoch: 0850 cost= 2.270251513 level0= 0.754586 pace0= 0.134198 alpha= 0.716171 beta= 0.648647\n",
      "Epoch: 0900 cost= 2.270249605 level0= 0.754702 pace0= 0.134299 alpha= 0.716824 beta= 0.647878\n",
      "Epoch: 0950 cost= 2.270248175 level0= 0.754798 pace0= 0.134383 alpha= 0.717367 beta= 0.64724\n",
      "Epoch: 1000 cost= 2.270247459 level0= 0.754878 pace0= 0.134453 alpha= 0.717819 beta= 0.646711\n",
      "Epoch: 1050 cost= 2.270246029 level0= 0.754945 pace0= 0.134511 alpha= 0.718193 beta= 0.646273\n",
      "Epoch: 1100 cost= 2.270246506 level0= 0.755001 pace0= 0.13456 alpha= 0.718505 beta= 0.645909\n",
      "Epoch: 1150 cost= 2.270245552 level0= 0.755048 pace0= 0.1346 alpha= 0.718764 beta= 0.645606\n",
      "Epoch: 1200 cost= 2.270245075 level0= 0.755086 pace0= 0.134634 alpha= 0.718979 beta= 0.645355\n",
      "Epoch: 1250 cost= 2.270244360 level0= 0.755118 pace0= 0.134662 alpha= 0.719158 beta= 0.645147\n",
      "Epoch: 1300 cost= 2.270245075 level0= 0.755145 pace0= 0.134685 alpha= 0.719307 beta= 0.644974\n",
      "Epoch: 1350 cost= 2.270245075 level0= 0.755167 pace0= 0.134704 alpha= 0.719431 beta= 0.64483\n",
      "Epoch: 1400 cost= 2.270244360 level0= 0.755186 pace0= 0.134721 alpha= 0.719533 beta= 0.64471\n",
      "Epoch: 1450 cost= 2.270244598 level0= 0.755201 pace0= 0.134734 alpha= 0.719619 beta= 0.64461\n",
      "Epoch: 1500 cost= 2.270244837 level0= 0.755214 pace0= 0.134745 alpha= 0.71969 beta= 0.644527\n",
      "Epoch: 1550 cost= 2.270244360 level0= 0.755225 pace0= 0.134755 alpha= 0.719749 beta= 0.644459\n",
      "Epoch: 1600 cost= 2.270243883 level0= 0.755233 pace0= 0.134762 alpha= 0.719798 beta= 0.644402\n",
      "Epoch: 1650 cost= 2.270245314 level0= 0.755241 pace0= 0.134769 alpha= 0.719839 beta= 0.644354\n",
      "Epoch: 1700 cost= 2.270244122 level0= 0.755247 pace0= 0.134774 alpha= 0.719873 beta= 0.644315\n",
      "Epoch: 1750 cost= 2.270244122 level0= 0.755253 pace0= 0.134778 alpha= 0.719901 beta= 0.644282\n",
      "Epoch: 1800 cost= 2.270245075 level0= 0.755256 pace0= 0.134782 alpha= 0.719925 beta= 0.644254\n",
      "Epoch: 1850 cost= 2.270244837 level0= 0.755259 pace0= 0.134785 alpha= 0.719944 beta= 0.644232\n",
      "Epoch: 1900 cost= 2.270244598 level0= 0.755262 pace0= 0.134788 alpha= 0.719961 beta= 0.644213\n",
      "Epoch: 1950 cost= 2.270245075 level0= 0.755265 pace0= 0.13479 alpha= 0.719974 beta= 0.644197\n",
      "Epoch: 2000 cost= 2.270245552 level0= 0.755268 pace0= 0.134791 alpha= 0.719985 beta= 0.644184\n",
      "Optimization Finished!\n",
      "Training cost= 2.27025 level0= 0.755268 pace0= 0.134791 alpha= 0.719985 beta= 0.644184\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "rng = np.random\n",
    "\n",
    "# Meta-parameters and debugging knobs\n",
    "learning_rate = 0.01\n",
    "training_epochs = 2000\n",
    "display_step = 50\n",
    "\n",
    "# Test data\n",
    "y = np.asarray([1, 1, 1, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "num_steps = y.shape[0]\n",
    "\n",
    "# Input data placeholders\n",
    "data_in = tf.placeholder('float')\n",
    "data_out = tf.placeholder('float')\n",
    "\n",
    "# ETS params\n",
    "level0 = tf.Variable(0.1 * rng.randn(), name = 'level0', dtype = tf.float32)\n",
    "pace0 = tf.Variable(0.1 * rng.randn(), name = 'pace0', dtype = tf.float32)\n",
    "alpha = tf.Variable(0.5, name = 'alpha', dtype = tf.float32)\n",
    "beta = tf.Variable(0.1, name = 'beta', dtype = tf.float32)\n",
    "\n",
    "# Definition of the ETS update\n",
    "def update(y, level, pace):\n",
    "    output = level + pace\n",
    "    new_level = alpha * y + (1 - alpha) * output\n",
    "    new_pace = beta * (new_level - level) + (1 - beta) * pace\n",
    "    return output, new_level, new_pace\n",
    "\n",
    "# Unrolled ETS loop\n",
    "outputs = []\n",
    "level, pace = level0, pace0\n",
    "for time_step in range(num_steps):\n",
    "    output, level, pace = update(data_in[time_step], level, pace)\n",
    "    outputs.append(output)\n",
    "\n",
    "# Mean squared error\n",
    "cost = tf.reduce_sum(tf.pow(tf.pack(outputs) - data_out, 2))\n",
    "\n",
    "# Gradient descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Fit the data.    \n",
    "    for epoch in range(training_epochs):\n",
    "        sess.run(optimizer, feed_dict={data_in: y, data_out: y})\n",
    "\n",
    "        # Display logs per epoch step\n",
    "        if (epoch + 1) % display_step == 0:\n",
    "            c = sess.run(cost, feed_dict={data_in: y, data_out: y})\n",
    "            print \"Epoch:\", '%04d' % (epoch+1), \\\n",
    "                \"cost=\", \"{:.9f}\".format(c), \\\n",
    "                \"level0=\", sess.run(level0), \\\n",
    "                \"pace0=\", sess.run(pace0), \\\n",
    "                \"alpha=\", sess.run(alpha), \\\n",
    "                \"beta=\", sess.run(beta)\n",
    "\n",
    "    print \"Optimization Finished!\"\n",
    "    training_cost = sess.run(cost, feed_dict={data_in: y, data_out: y})\n",
    "    print \"Training cost=\", training_cost, \\\n",
    "        \"level0=\", sess.run(level0), \\\n",
    "        \"pace0=\", sess.run(pace0), \\\n",
    "        \"alpha=\", sess.run(alpha), \\\n",
    "        \"beta=\", sess.run(beta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Okay, so**\n",
    "\n",
    "That is not quite a match, but many of the components are the same. The results from R are actually:\n",
    "```R\n",
    "> ets(c(1, 1, 1, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10), model = 'AAN')\n",
    "ETS(A,A,N) \n",
    "\n",
    "Call:\n",
    " ets(y = c(1, 1, 1, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10), model = \"AAN\") \n",
    "\n",
    "  Smoothing parameters:\n",
    "    alpha = 0.7199 \n",
    "    beta  = 0.4639 \n",
    "\n",
    "  Initial states:\n",
    "    l = 0.7554 \n",
    "    b = 0.1348 \n",
    "\n",
    "  sigma:  0.4027\n",
    "\n",
    "     AIC     AICc      BIC \n",
    "21.47843 28.97843 24.67371 \n",
    "```\n",
    "Based on a cursory look (need more digging) the model here is slightly better for reducing squared error. But I also imagine that the trend component is not particularly significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
